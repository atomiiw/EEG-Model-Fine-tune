{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "atw1Sidiy64K",
        "xKm5Q8Tu0yuv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the folder"
      ],
      "metadata": {
        "id": "atw1Sidiy64K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npA0ADiOcx9w",
        "outputId": "49e39d37-e9ad-4c83-f81f-5b40f98a7448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/atomiiw/EEG-Model-Fine-tune.git"
      ],
      "metadata": {
        "id": "fnuMqE_u9RiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce82c57-0d8c-424b-caf8-090cc36c42ba"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'EEG-Model-Fine-tune' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd EEG-Model-Fine-tune/MIRepNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tamWZhTF0O1",
        "outputId": "a6ddbc7e-80fa-4e23-b8da-6f016d547c85"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EEG-Model-Fine-tune/MIRepNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r MIRepNet/requirements.txt"
      ],
      "metadata": {
        "id": "x3hU08tSF3hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Performance: Before Fine-tuning\n",
        "Current output: among {0, 1, 2, 3}   \n",
        "Expected output: among {0, 1, ..., 7, 8}   \n",
        "Current accuracy: 8%-15%   \n",
        "Accuracy if just randomly guessing: 11%     \n",
        "\n",
        "Why does accuracy differ every time?  \n",
        "'Loaded 108/110 parameters from pretrained model'   \n",
        "The 2 final layer weights are randomly initialized\n"
      ],
      "metadata": {
        "id": "xKm5Q8Tu0yuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Working dir:\", os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLMTLIF4Kxh5",
        "outputId": "583670b7-63dd-4cfa-8dda-a418141edcae"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working dir: /content/EEG-Model-Fine-tune/MIRepNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from model.mlm import mlm_mask\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ==== CONFIG ====\n",
        "DATASET_NAME = \"basic\"\n",
        "WEIGHT_PATH = \"weight/MIRepNet.pth\"   # pretrained weights (4-class)\n",
        "BATCH_SIZE = 32\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ==== LOAD DATA ====\n",
        "X = np.load(f'data/{DATASET_NAME}/X_test.npy')   # (N, 128, 200)\n",
        "y = np.load(f'data/{DATASET_NAME}/labels_test.npy')  # (N,)\n",
        "print(\"Loaded data:\", X.shape, y.shape)\n",
        "\n",
        "# convert to tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# ==== LOAD MODEL ====\n",
        "model = mlm_mask(\n",
        "    emb_size=256,\n",
        "    depth=6,\n",
        "    n_classes=4,     # pretrained model expects 4 outputs\n",
        "    pretrainmode=False,\n",
        "    pretrain=WEIGHT_PATH\n",
        ").to(DEVICE)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# ==== EVALUATE ====\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, labels in loader:\n",
        "        data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
        "        _, outputs = model(data)\n",
        "        # expected to return amongst {0, 1, 2, 3}\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = correct / total * 100\n",
        "print(f\"\\n‚úÖ Raw pretrained MIRepNet accuracy on your dataset: {accuracy:.2f}%\")\n",
        "print(f\"Correct: {correct} / {total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E55nG5tE0x0h",
        "outputId": "e59dd0ad-38d5-4712-b89c-6bea987baecf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded data: (144, 128, 200) (144,)\n",
            "Loaded 108/110 parameters from pretrained model\n",
            "\n",
            "‚úÖ Raw pretrained MIRepNet accuracy on your dataset: 11.81%\n",
            "Correct: 17 / 144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train across all patients"
      ],
      "metadata": {
        "id": "Y-Fsq8PizA7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MIRepNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6POvj8ZAMupq",
        "outputId": "194bc78c-f86c-4b98-cf26-b16b143e9963"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'MIRepNet'\n",
            "/content/EEG-Model-Fine-tune/MIRepNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python finetune.py --dataset_name basic --model_name MIRepNet --num_classes 9 --val_split 0.8 --epochs 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW_AjaqWdwCg",
        "outputId": "f7de8121-3b4f-4c70-fda1-032aaa12adac"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting EEG Classification with Configurable Hyperparameters\n",
            "\n",
            "original data shape: (1096, 128, 200) labels shape: (1096,)\n",
            "preprocessed data shape: (1096, 128, 200) preprocessed labels shape: (1096,)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Loaded 108/110 parameters from pretrained model\n",
            "Seed: 666, Subject: 0\n",
            "\n",
            "Predicted: [5 5 5 7 5 5 5 5 7 5 5 7 5 5 5 5 5 5 5 5 5 5 5 7 7 5 5 5 5 5 5 7]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 102 out of 877 correct. Accuracy: 11.630558722919043.\n",
            "Predicted: [7 6 3 7 3 3 3 3 7 3 1 7 5 7 8 3 3 5 3 3 3 3 3 2 8 8 3 5 3 3 3 3]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 126 out of 877 correct. Accuracy: 14.367160775370582.\n",
            "Predicted: [3 3 3 3 3 3 3 3 3 3 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 127 out of 877 correct. Accuracy: 14.481185860889395.\n",
            "Predicted: [7 3 7 7 7 7 3 5 7 7 7 3 7 7 3 7 7 5 3 7 7 7 7 3 7 3 3 7 5 3 3 3]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 127 out of 877 correct. Accuracy: 14.481185860889395.\n",
            "Predicted: [7 3 3 7 3 3 3 5 7 3 7 3 5 3 3 3 7 5 3 3 7 3 3 3 3 3 3 5 3 3 3 3]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 127 out of 877 correct. Accuracy: 14.481185860889395.\n",
            "Predicted: [5 3 5 3 3 3 3 5 7 3 5 3 5 3 3 5 5 5 0 3 7 3 3 3 3 3 3 5 0 3 3 3]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 114 out of 877 correct. Accuracy: 12.998859749144811.\n",
            "Predicted: [5 3 5 7 3 3 0 5 7 3 5 7 5 7 3 5 5 5 0 3 5 7 7 2 7 3 3 5 0 3 3 3]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 112 out of 877 correct. Accuracy: 12.770809578107183.\n",
            "Predicted: [5 3 3 3 3 3 3 5 7 3 5 3 5 3 3 5 5 5 3 3 5 3 3 3 3 3 3 5 0 3 3 3]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 117 out of 877 correct. Accuracy: 13.340935005701255.\n",
            "Predicted: [5 3 3 3 3 3 3 3 7 3 5 3 5 3 3 3 3 5 3 3 5 3 3 3 3 3 3 5 3 3 3 3]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 127 out of 877 correct. Accuracy: 14.481185860889395.\n",
            "Predicted: [3 3 3 3 3 3 3 3 7 3 5 3 3 3 3 3 3 5 3 3 5 3 3 3 3 3 3 5 3 3 3 3]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 130 out of 877 correct. Accuracy: 14.823261117445838.\n",
            "Saved fine-tuned weights to ./weight/basic_MIRepNet_finetuned.pth\n",
            "Results saved to ./result/acc/basic_MIRepNet_2025-10-30_22-32-22_results.csv\n",
            "Experiment completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train on each patient individually\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SqCPyN39_vSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python finetune.py --dataset_name S14_testing --model_name MIRepNet --num_classes 9 --val_split 0.2 --epochs 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTMSqaMV_zR4",
        "outputId": "8f6e99c9-3290-4a07-8882-2b52385560b6"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting EEG Classification with Configurable Hyperparameters\n",
            "\n",
            "original data shape: (1290, 128, 200) labels shape: (1290,)\n",
            "preprocessed data shape: (1290, 128, 200) preprocessed labels shape: (1290,)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "üîß Using local process_and_replace_loader from finetune.py\n",
            "üîß Using local process_and_replace_loader from finetune.py\n",
            "‚úÖ Saved EA matrix to ./weight/S14_testing_EA_matrix.npy\n",
            "Loaded 108/110 parameters from pretrained model\n",
            "Seed: 666, Subject: 0\n",
            "\n",
            "Predicted: [3 0 0 7 8 0 7 0 7 6 0 6 0 6 8 6 2 4 6 7 3 4 8 5 8 0 4 5 0 8 0 5]\n",
            "Actual:    [3 8 0 2 2 7 7 0 2 6 8 6 0 6 2 6 8 4 6 2 3 4 8 5 2 8 4 6 6 8 0 5]\n",
            "Got 164 out of 258 correct. Accuracy: 63.565891472868216.\n",
            "Predicted: [3 8 0 2 2 8 7 0 2 6 8 6 0 6 2 6 8 4 6 2 3 4 8 5 2 8 4 5 6 8 0 5]\n",
            "Actual:    [3 8 0 2 2 7 7 0 2 6 8 6 0 6 2 6 8 4 6 2 3 4 8 5 2 8 4 6 6 8 0 5]\n",
            "Got 227 out of 258 correct. Accuracy: 87.98449612403101.\n",
            "Predicted: [3 8 0 2 2 7 7 0 2 6 8 6 0 6 2 6 8 4 6 2 3 4 8 5 2 8 4 6 6 8 0 5]\n",
            "Actual:    [3 8 0 2 2 7 7 0 2 6 8 6 0 6 2 6 8 4 6 2 3 4 8 5 2 8 4 6 6 8 0 5]\n",
            "Got 247 out of 258 correct. Accuracy: 95.73643410852713.\n",
            "Predicted: [3 8 0 2 2 7 7 0 2 6 8 6 0 6 2 6 8 4 6 2 3 4 8 5 2 8 4 6 6 8 0 5]\n",
            "Actual:    [3 8 0 2 2 7 7 0 2 6 8 6 0 6 2 6 8 4 6 2 3 4 8 5 2 8 4 6 6 8 0 5]\n",
            "Got 251 out of 258 correct. Accuracy: 97.28682170542635.\n",
            "Predicted: [3 8 0 2 2 7 7 0 2 6 8 6 0 6 2 6 8 4 6 2 3 4 8 5 2 8 4 6 6 8 0 5]\n",
            "Actual:    [3 8 0 2 2 7 7 0 2 6 8 6 0 6 2 6 8 4 6 2 3 4 8 5 2 8 4 6 6 8 0 5]\n",
            "Got 255 out of 258 correct. Accuracy: 98.83720930232558.\n",
            "Saved fine-tuned weights to ./weight/S14_testing_MIRepNet_finetuned.pth\n",
            "Results saved to ./result/acc/S14_testing_MIRepNet_2025-10-31_02-52-49_results.csv\n",
            "Experiment completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test on new data"
      ],
      "metadata": {
        "id": "3jwoWlye7I05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from scipy.linalg import fractional_matrix_power\n",
        "from model.mlm import mlm_mask\n",
        "from utils.channel_list import use_channels_names, channel_positions\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "# ==== CONFIG ====\n",
        "DATASET_NAME = \"S14_testing\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ==== Load data ====\n",
        "X = np.load(f\"data/{DATASET_NAME}/X.npy\")  # (N,128,200)\n",
        "y = np.load(f\"data/{DATASET_NAME}/labels.npy\")\n",
        "\n",
        "# ==== 1Ô∏è‚É£ Apply Euclidean Alignment (exactly same direction) ====\n",
        "refEA = np.load(f\"weight/{DATASET_NAME}_EA_matrix.npy\")\n",
        "X_ea = np.zeros_like(X)\n",
        "for i in range(X.shape[0]):\n",
        "    X_ea[i] = np.dot(refEA, X[i])    # same as training (not transposed)\n",
        "\n",
        "# ==== 2Ô∏è‚É£ Channel interpolation to 45 channels ====\n",
        "def pad_missing_channels_diff(x, target_channels, actual_channels):\n",
        "    B, C, T = x.shape\n",
        "    existing_pos = np.array([channel_positions[ch] for ch in actual_channels])\n",
        "    target_pos = np.array([channel_positions[ch] for ch in target_channels])\n",
        "\n",
        "    W = np.zeros((len(target_channels), C))\n",
        "    for i, (target_ch, pos) in enumerate(zip(target_channels, target_pos)):\n",
        "        if target_ch in actual_channels:\n",
        "            src_idx = actual_channels.index(target_ch)\n",
        "            W[i, src_idx] = 1.0\n",
        "        else:\n",
        "            dist = cdist([pos], existing_pos)[0]\n",
        "            weights = 1 / (dist + 1e-6)\n",
        "            weights /= weights.sum()\n",
        "            W[i] = weights\n",
        "\n",
        "    padded = np.zeros((B, len(target_channels), T))\n",
        "    for b in range(B):\n",
        "        padded[b] = W @ x[b]\n",
        "    return padded\n",
        "\n",
        "X_final = pad_missing_channels_diff(X_ea, use_channels_names, use_channels_names)\n",
        "print(\"Shape after projection:\", X_final.shape)  # (N,45,200)\n",
        "\n",
        "# ==== 3Ô∏è‚É£ Convert to tensors ====\n",
        "X_tensor = torch.tensor(X_final, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "loader = DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=32)\n",
        "\n",
        "# ==== 4Ô∏è‚É£ Load model ====\n",
        "model = mlm_mask(emb_size=256, depth=6, n_classes=9, pretrainmode=False).to(DEVICE)\n",
        "model.load_state_dict(torch.load(f\"weight/{DATASET_NAME}_MIRepNet_finetuned.pth\", map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "# ==== 5Ô∏è‚É£ Evaluate ====\n",
        "correct = total = 0\n",
        "with torch.no_grad():\n",
        "    for data, labels in loader:\n",
        "        data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
        "        _, outputs = model(data)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "acc = correct / total * 100\n",
        "print(f\"‚úÖ Test accuracy on {DATASET_NAME}: {acc:.2f}% ({correct}/{total})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve19iQ1K7Q47",
        "outputId": "acd8b6e3-9bd3-4869-870d-bfcbe38b8d45"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after projection: (1290, 45, 200)\n",
            "‚úÖ Test accuracy on S14_testing: 99.22% (1280/1290)\n"
          ]
        }
      ]
    }
  ]
}