{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "atw1Sidiy64K",
        "xKm5Q8Tu0yuv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the folder"
      ],
      "metadata": {
        "id": "atw1Sidiy64K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npA0ADiOcx9w",
        "outputId": "c367cca2-87a7-4bae-a24a-aaf865145d32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/atomiiw/EEG-Model-Fine-tune.git"
      ],
      "metadata": {
        "id": "fnuMqE_u9RiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f679e850-207a-469e-f72f-2e6d25f27609"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EEG-Model-Fine-tune'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 35 (delta 1), reused 35 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (35/35), 958.75 KiB | 43.58 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd EEG-Model-Fine-tune"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tamWZhTF0O1",
        "outputId": "d30a6bac-829b-433a-83c6-7fd805f2f7e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EEG-Model-Fine-tune\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r MIRepNet/requirements.txt"
      ],
      "metadata": {
        "id": "x3hU08tSF3hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Performance: Before Fine-tuning\n",
        "Current output: among {0, 1, 2, 3}   \n",
        "Expected output: among {0, 1, ..., 7, 8}   \n",
        "Current accuracy: 8%-15%   \n",
        "Accuracy if just randomly guessing: 11%     \n",
        "\n",
        "Why does accuracy differ every time?  \n",
        "'Loaded 108/110 parameters from pretrained model'   \n",
        "The 2 final layer weights are randomly initialized\n"
      ],
      "metadata": {
        "id": "xKm5Q8Tu0yuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Working dir:\", os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLMTLIF4Kxh5",
        "outputId": "4f4481d1-fbb6-41ab-928b-a68d2ce3efda"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working dir: /content/EEG-Model-Fine-tune\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from model.mlm import mlm_mask\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ==== CONFIG ====\n",
        "DATASET_NAME = \"basic\"\n",
        "WEIGHT_PATH = \"weight/MIRepNet.pth\"   # pretrained weights (4-class)\n",
        "BATCH_SIZE = 32\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ==== LOAD DATA ====\n",
        "X = np.load(f'data/{DATASET_NAME}/X_test.npy')   # (N, 128, 200)\n",
        "y = np.load(f'data/{DATASET_NAME}/labels_test.npy')  # (N,)\n",
        "print(\"Loaded data:\", X.shape, y.shape)\n",
        "\n",
        "# convert to tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# ==== LOAD MODEL ====\n",
        "model = mlm_mask(\n",
        "    emb_size=256,\n",
        "    depth=6,\n",
        "    n_classes=4,     # pretrained model expects 4 outputs\n",
        "    pretrainmode=False,\n",
        "    pretrain=WEIGHT_PATH\n",
        ").to(DEVICE)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# ==== EVALUATE ====\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, labels in loader:\n",
        "        data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
        "        _, outputs = model(data)\n",
        "        # expected to return amongst {0, 1, 2, 3}\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = correct / total * 100\n",
        "print(f\"\\n‚úÖ Raw pretrained MIRepNet accuracy on your dataset: {accuracy:.2f}%\")\n",
        "print(f\"Correct: {correct} / {total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E55nG5tE0x0h",
        "outputId": "44c585d0-1d56-4323-c6e4-34ce2cabd87b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded data: (144, 128, 200) (144,)\n",
            "Loaded 108/110 parameters from pretrained model\n",
            "\n",
            "‚úÖ Raw pretrained MIRepNet accuracy on your dataset: 11.81%\n",
            "Correct: 17 / 144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BASIC: Fine-tune"
      ],
      "metadata": {
        "id": "Y-Fsq8PizA7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MIRepNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6POvj8ZAMupq",
        "outputId": "36f73b0a-eeb5-4d0d-8cb4-b99cebe6abff"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EEG-Model-Fine-tune/MIRepNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python finetune.py --dataset_name basic --model_name MIRepNet --num_classes 9 --val_split 0.8 --epochs 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW_AjaqWdwCg",
        "outputId": "759c830d-ce3e-4be5-ac82-735510aab9d6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting EEG Classification with Configurable Hyperparameters\n",
            "\n",
            "original data shape: (1096, 128, 200) labels shape: (1096,)\n",
            "preprocessed data shape: (1096, 128, 200) preprocessed labels shape: (1096,)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "before processedÔºö (219, 128, 200)\n",
            "after processedÔºö (219, 45, 200)\n",
            "before processedÔºö (877, 128, 200)\n",
            "after processedÔºö (877, 45, 200)\n",
            "Loaded 108/110 parameters from pretrained model\n",
            "Seed: 666, Subject: 0\n",
            "\n",
            "Predicted: [5 1 7 6 0 5 8 2 5 7 5 0 5 5 0 7 5 7 1 0 7 5 5 2 5 7 5 5 7 5 2 8]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 95 out of 877 correct. Accuracy: 10.832383124287343.\n",
            "Predicted: [7 1 7 6 6 6 0 4 0 1 1 0 7 7 4 1 7 7 1 6 7 7 5 4 7 7 5 5 4 3 3 4]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 95 out of 877 correct. Accuracy: 10.832383124287343.\n",
            "Predicted: [3 3 7 2 3 3 0 2 5 3 7 0 7 7 0 4 6 2 3 6 4 2 5 2 3 4 4 5 4 3 3 4]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 102 out of 877 correct. Accuracy: 11.630558722919043.\n",
            "Predicted: [7 0 7 2 0 3 0 2 5 7 7 0 7 7 0 0 7 2 1 0 4 7 5 2 2 7 3 8 0 3 1 4]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 111 out of 877 correct. Accuracy: 12.656784492588368.\n",
            "Predicted: [6 1 7 2 0 3 0 2 5 3 1 0 7 7 4 4 7 2 1 4 4 7 5 3 2 4 4 8 4 3 1 4]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 107 out of 877 correct. Accuracy: 12.200684150513112.\n",
            "Predicted: [5 1 7 2 0 5 0 2 5 7 1 0 7 7 1 4 7 2 1 0 7 5 5 2 2 7 5 5 1 3 1 4]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 108 out of 877 correct. Accuracy: 12.314709236031927.\n",
            "Predicted: [7 1 7 2 0 5 0 2 5 3 4 0 7 7 4 4 7 2 1 6 7 7 5 5 0 7 3 5 4 3 1 4]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 108 out of 877 correct. Accuracy: 12.314709236031927.\n",
            "Predicted: [7 1 7 2 0 5 0 2 5 3 4 3 7 7 4 4 7 2 1 6 7 7 5 5 3 7 5 5 4 3 1 4]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 110 out of 877 correct. Accuracy: 12.542759407069557.\n",
            "Predicted: [7 1 7 2 0 5 0 2 5 3 4 3 7 7 4 4 7 2 1 6 7 7 5 5 3 7 5 5 4 3 3 6]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 106 out of 877 correct. Accuracy: 12.086659064994299.\n",
            "Predicted: [7 1 7 2 3 3 0 2 5 3 4 3 7 7 4 4 7 2 1 6 7 7 5 5 3 7 3 5 4 3 1 4]\n",
            "Actual:    [5 0 6 1 3 5 3 0 1 1 8 1 8 2 6 7 2 8 2 4 6 7 5 4 7 5 2 3 7 7 8 3]\n",
            "Got 112 out of 877 correct. Accuracy: 12.770809578107183.\n",
            "Saved fine-tuned weights to ./weight/basic_MIRepNet_finetuned.pth\n",
            "Results saved to ./result/acc/basic_MIRepNet_2025-10-30_22-22-36_results.csv\n",
            "Experiment completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BASIC: Load the fine-tuned weights & test on full dataset"
      ],
      "metadata": {
        "id": "SqCPyN39_vSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from utils.utils import process_and_replace_loader\n",
        "from model.mlm import mlm_mask\n",
        "\n",
        "# ==== CONFIG ====\n",
        "DATASET_NAME = \"mydata_test\"\n",
        "WEIGHT_PATH = \"./weight/mydata_MIRepNet_finetuned.pth\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# ==== LOAD RAW DATA ====\n",
        "X = np.load(f'./data/{DATASET_NAME}/X.npy')\n",
        "y = np.load(f'./data/{DATASET_NAME}/labels.npy')\n",
        "print(\"Loaded:\", X.shape, y.shape)\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "loader = DataLoader(TensorDataset(X_tensor, y_tensor),\n",
        "                    batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# ==== PREPROCESS (same as training) ====\n",
        "loader = process_and_replace_loader(loader,\n",
        "                                    ischangechn=True,\n",
        "                                    dataset=DATASET_NAME)\n",
        "\n",
        "# ==== LOAD MODEL ====\n",
        "model = mlm_mask(\n",
        "    emb_size=256,\n",
        "    depth=6,\n",
        "    n_classes=9,\n",
        "    pretrainmode=False,\n",
        "    pretrain=None\n",
        ").to(DEVICE)\n",
        "\n",
        "model.load_state_dict(torch.load(WEIGHT_PATH))\n",
        "model.eval()\n",
        "\n",
        "# ==== EVALUATE ====\n",
        "correct, total = 0, 0\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, labels in loader:\n",
        "        data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
        "        _, outputs = model(data)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = correct / total * 100\n",
        "print(f\"\\nüéØ Accuracy on preprocessed data: {accuracy:.2f}% \"\n",
        "      f\"({correct}/{total})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTMSqaMV_zR4",
        "outputId": "d518f363-2eaf-4867-8574-b5c15c758cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: (346, 111, 200) (346,)\n",
            "before processedÔºö (346, 111, 200)\n",
            "after processedÔºö (346, 45, 200)\n",
            "\n",
            "üéØ Accuracy on preprocessed data: 91.62% (317/346)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split out a separate test set, provided a test ratio"
      ],
      "metadata": {
        "id": "uXrTgCfxHROl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# ==== CONFIG ====\n",
        "train_ratio = 0.9   # e.g. 0.9 for 90% train / 10% test\n",
        "data_dir = \"./data/mydata\"\n",
        "test_dir = \"./data/mydata_test\"\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# ==== LOAD ====\n",
        "def load_or_empty(folder):\n",
        "    X_path, y_path = f\"{folder}/X.npy\", f\"{folder}/labels.npy\"\n",
        "    if os.path.exists(X_path) and os.path.exists(y_path):\n",
        "        return np.load(X_path), np.load(y_path)\n",
        "    return np.empty((0,)), np.empty((0,))\n",
        "\n",
        "X_train_old, y_train_old = load_or_empty(data_dir)\n",
        "X_test_old, y_test_old = load_or_empty(test_dir)\n",
        "\n",
        "# ==== MERGE ====\n",
        "if X_train_old.size == 0 and X_test_old.size == 0:\n",
        "    raise FileNotFoundError(\"‚ùå No data found in mydata/ or mydata_test/\")\n",
        "elif X_test_old.size == 0:\n",
        "    print(\"‚ÑπÔ∏è Only found mydata/, splitting it now...\")\n",
        "    X_full, y_full = X_train_old, y_train_old\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Found both mydata/ and mydata_test/, merging before re-split...\")\n",
        "    X_full = np.concatenate([X_train_old, X_test_old])\n",
        "    y_full = np.concatenate([y_train_old, y_test_old])\n",
        "\n",
        "print(f\"\\nüì¶ Total samples: {len(y_full)} | Shape: {X_full.shape}\")\n",
        "\n",
        "# ==== SPLIT ====\n",
        "test_ratio = 1 - train_ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_full, y_full, test_size=test_ratio, random_state=42, stratify=y_full\n",
        ")\n",
        "\n",
        "# ==== SAVE ====\n",
        "np.save(f\"{data_dir}/X.npy\", X_train)\n",
        "np.save(f\"{data_dir}/labels.npy\", y_train)\n",
        "np.save(f\"{test_dir}/X.npy\", X_test)\n",
        "np.save(f\"{test_dir}/labels.npy\", y_test)\n",
        "\n",
        "# ==== REPORT ====\n",
        "print(f\"\\n‚úÖ Split complete:\")\n",
        "print(f\"Train set: {X_train.shape}, Labels: {y_train.shape}\")\n",
        "print(f\"Test set:  {X_test.shape}, Labels: {y_test.shape}\")\n",
        "print(f\"\\nüéØ {train_ratio*100:.0f}% train / {test_ratio*100:.0f}% test split saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1_wF-LQHXTy",
        "outputId": "b48deddd-861f-4b3a-d9a1-55e797fa91bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ÑπÔ∏è Only found mydata/, splitting it now...\n",
            "\n",
            "üì¶ Total samples: 3456 | Shape: (3456, 111, 200)\n",
            "\n",
            "‚úÖ Split complete:\n",
            "Train set: (3110, 111, 200), Labels: (3110,)\n",
            "Test set:  (346, 111, 200), Labels: (346,)\n",
            "\n",
            "üéØ 90% train / 10% test split saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git rm --cached \"preprocess data/pt_decoding_data_S62.pkl\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvaGm16BxvzQ",
        "outputId": "296913c0-e374-4c7e-802a-94f803ed0e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: pathspec 'preprocess data/pt_decoding_data_S62.pkl' did not match any files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdY4k8oGxANe",
        "outputId": "2d96db8e-3fc5-4f3a-f932-5020b64461e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch master\n",
            "\n",
            "No commits yet\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git rm --cached <file>...\" to unstage)\n",
            "\t\u001b[32mnew file:   .gitignore\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet.md\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/.gitignore\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/LICENSE\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/MIRepNet_Finetuning.ipynb\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/README.md\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/asset/1\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/asset/Datasets.jpg\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/asset/High-quality_Data_Construction.jpg\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/asset/Main_Results.jpg\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/asset/RepMI.jpg\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/dataset.py\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/finetune.py\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/model/ADFCNN.py\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/model/Conformer.py\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/model/Deep_Shallow_Conv.py\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/model/EDPNet.py\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/model/EEGNet.py\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/model/FBCNet.py\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/model/IFNet.py\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/model/mlm.py\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/requirements.txt\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/results.jpg\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/utils/channel_list.py\u001b[m\n",
            "\t\u001b[32mnew file:   MIRepNet/utils/utils.py\u001b[m\n",
            "\t\u001b[32mnew file:   preprocess data/produce_dataset.ipynb\u001b[m\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   .gitignore\u001b[m\n",
            "\t\u001b[31mmodified:   MIRepNet/MIRepNet_Finetuning.ipynb\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mpreprocess data/pt_decoding_data_S62.pkl\u001b[m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PATIENT: Establish Datasets"
      ],
      "metadata": {
        "id": "9px18BziicM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from utils.utils import process_and_replace_loader\n",
        "\n",
        "# ==== CONFIG ====\n",
        "DATA_DIR = \"./data/mydata_patients\"\n",
        "TRAIN_SAVE_DIR = \"./data/mydata_patients_train\"\n",
        "TEST_SAVE_DIR = \"./data/mydata_patients_test\"\n",
        "DATASET_NAME = \"mydata\"\n",
        "HELD_OUT = \"S26\"   # choose which patient to hold out for testing\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "os.makedirs(TRAIN_SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(TEST_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ==== Helper Functions ====\n",
        "def load_patient(pid):\n",
        "    \"\"\"Load one patient's X and y arrays.\"\"\"\n",
        "    X = np.load(os.path.join(DATA_DIR, f\"X_{pid}.npy\"))\n",
        "    y = np.load(os.path.join(DATA_DIR, f\"y_{pid}.npy\"))\n",
        "    print(f\"Loaded {pid}: X={X.shape}, y={y.shape}\")\n",
        "    return X, y\n",
        "\n",
        "def preprocess_patient(X, y):\n",
        "    \"\"\"Apply EA + channel alignment (ischangechn=True)\"\"\"\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "    loader = DataLoader(TensorDataset(X_tensor, y_tensor),\n",
        "                        batch_size=BATCH_SIZE, shuffle=False)\n",
        "    loader = process_and_replace_loader(loader,\n",
        "                                        ischangechn=True,\n",
        "                                        dataset=DATASET_NAME)\n",
        "    all_X, all_y = [], []\n",
        "    for xb, yb in loader:\n",
        "        all_X.append(xb.numpy())\n",
        "        all_y.append(yb.numpy())\n",
        "    return np.concatenate(all_X), np.concatenate(all_y)\n",
        "\n",
        "# ==== Load all patients and preprocess ====\n",
        "patients = [f.split(\"_\")[1].split(\".\")[0] for f in os.listdir(DATA_DIR) if f.startswith(\"X_\")]\n",
        "\n",
        "train_X, train_y = [], []\n",
        "for pid in patients:\n",
        "    X, y = load_patient(pid)\n",
        "    Xp, yp = preprocess_patient(X, y)\n",
        "    if pid == HELD_OUT:\n",
        "        # save test set separately\n",
        "        np.save(os.path.join(TEST_SAVE_DIR, \"X.npy\"), Xp)\n",
        "        np.save(os.path.join(TEST_SAVE_DIR, \"labels.npy\"), yp)\n",
        "        print(f\"‚úÖ Saved test set for {pid}: {Xp.shape}\")\n",
        "    else:\n",
        "        train_X.append(Xp)\n",
        "        train_y.append(yp)\n",
        "        print(f\"Added {pid} to training pool ({Xp.shape})\")\n",
        "\n",
        "# ==== Combine train patients ====\n",
        "X_train = np.concatenate(train_X)\n",
        "y_train = np.concatenate(train_y)\n",
        "print(f\"\\nCombined train shape: X={X_train.shape}, y={y_train.shape}\")\n",
        "\n",
        "# ==== Save train set ====\n",
        "np.save(os.path.join(TRAIN_SAVE_DIR, \"X.npy\"), X_train)\n",
        "np.save(os.path.join(TRAIN_SAVE_DIR, \"labels.npy\"), y_train)\n",
        "print(f\"‚úÖ Saved train set to {TRAIN_SAVE_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THrxamZEigqw",
        "outputId": "09170721-5061-47cf-fb7c-944095ed5728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded S14: X=(432, 111, 200), y=(432,)\n",
            "before processedÔºö (432, 111, 200)\n",
            "after processedÔºö (432, 45, 200)\n",
            "Added S14 to training pool ((432, 45, 200))\n",
            "Loaded S39: X=(411, 144, 200), y=(411,)\n",
            "before processedÔºö (411, 144, 200)\n",
            "after processedÔºö (411, 45, 200)\n",
            "Added S39 to training pool ((411, 45, 200))\n",
            "Loaded S22: X=(453, 74, 200), y=(453,)\n",
            "before processedÔºö (453, 74, 200)\n",
            "after processedÔºö (453, 45, 200)\n",
            "Added S22 to training pool ((453, 45, 200))\n",
            "Loaded S23: X=(453, 63, 200), y=(453,)\n",
            "before processedÔºö (453, 63, 200)\n",
            "after processedÔºö (453, 45, 200)\n",
            "Added S23 to training pool ((453, 45, 200))\n",
            "Loaded S58: X=(423, 171, 200), y=(423,)\n",
            "before processedÔºö (423, 171, 200)\n",
            "after processedÔºö (423, 45, 200)\n",
            "Added S58 to training pool ((423, 45, 200))\n",
            "Loaded S62: X=(534, 201, 200), y=(534,)\n",
            "before processedÔºö (534, 201, 200)\n",
            "after processedÔºö (534, 45, 200)\n",
            "Added S62 to training pool ((534, 45, 200))\n",
            "Loaded S33: X=(138, 149, 200), y=(138,)\n",
            "before processedÔºö (138, 149, 200)\n",
            "after processedÔºö (138, 45, 200)\n",
            "Added S33 to training pool ((138, 45, 200))\n",
            "Loaded S26: X=(444, 111, 200), y=(444,)\n",
            "before processedÔºö (444, 111, 200)\n",
            "after processedÔºö (444, 45, 200)\n",
            "‚úÖ Saved test set for S26: (444, 45, 200)\n",
            "\n",
            "Combined train shape: X=(2844, 45, 200), y=(2844,)\n",
            "‚úÖ Saved train set to ./data/mydata_patients_train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QanN4QFNqSt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train on majority & evaluate on held-out patients"
      ],
      "metadata": {
        "id": "qIILLm4DmuxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python finetune.py \\\n",
        "    --dataset_name mydata_patients_train \\\n",
        "    --model_name MIRepNet \\\n",
        "    --num_classes 9 \\\n",
        "    --val_split 0.8 \\\n",
        "    --epochs 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHFRr-4Rn793",
        "outputId": "7e4de7a7-23c2-4089-de64-2079f0a17461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting EEG Classification with Configurable Hyperparameters\n",
            "\n",
            "original data shape: (2844, 45, 200) labels shape: (2844,)\n",
            "preprocessed data shape: (2844, 45, 200) preprocessed labels shape: (2844,)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "before processedÔºö (568, 45, 200)\n",
            "after processedÔºö (568, 45, 200)\n",
            "before processedÔºö (2276, 45, 200)\n",
            "after processedÔºö (2276, 45, 200)\n",
            "Loaded 108/110 parameters from pretrained model\n",
            "Seed: 666, Subject: 0\n",
            "\n",
            "Predicted: [1 7 4 1 1 4 4 1 7 1 7 1 1 7 5 7 7 7 4 7 7 1 4 7 4 7 1 3 7 1 4 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 273 out of 2276 correct. Accuracy: 11.994727592267134.\n",
            "Predicted: [0 1 1 1 1 1 3 1 5 1 0 3 1 3 1 0 5 4 3 8 5 8 3 1 3 1 1 3 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 271 out of 2276 correct. Accuracy: 11.906854130052725.\n",
            "Predicted: [0 1 1 1 1 1 2 0 1 1 2 1 1 7 2 1 1 5 3 7 5 1 7 1 1 1 1 2 3 1 7 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 265 out of 2276 correct. Accuracy: 11.64323374340949.\n",
            "Predicted: [0 1 2 3 4 5 3 0 5 1 2 1 5 2 2 2 6 2 3 5 3 2 6 1 8 2 2 3 0 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 259 out of 2276 correct. Accuracy: 11.379613356766257.\n",
            "Predicted: [0 5 2 5 1 5 3 0 5 0 5 1 5 3 2 2 6 5 3 5 5 2 6 8 3 5 2 3 0 6 3 5]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 260 out of 2276 correct. Accuracy: 11.423550087873462.\n",
            "Predicted: [0 1 2 1 4 5 6 0 5 1 4 4 5 3 2 2 6 0 3 6 3 1 6 1 5 8 2 4 0 6 8 6]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 241 out of 2276 correct. Accuracy: 10.588752196836555.\n",
            "Predicted: [0 8 3 3 1 4 4 0 5 0 3 0 5 3 3 0 5 5 3 5 3 1 0 8 5 5 2 4 0 8 8 5]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 245 out of 2276 correct. Accuracy: 10.764499121265377.\n",
            "Predicted: [0 1 0 3 4 4 3 0 5 0 0 0 7 3 3 0 5 5 3 1 0 1 3 8 1 1 1 4 3 6 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 253 out of 2276 correct. Accuracy: 11.115992970123024.\n",
            "Predicted: [0 1 2 5 4 5 0 0 5 0 2 1 1 3 2 0 5 5 3 5 5 1 5 1 5 1 1 4 7 3 1 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 233 out of 2276 correct. Accuracy: 10.23725834797891.\n",
            "Predicted: [3 4 2 5 4 4 3 0 5 0 2 1 7 3 5 0 5 5 3 3 4 2 7 8 1 8 2 4 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 263 out of 2276 correct. Accuracy: 11.555360281195078.\n",
            "Predicted: [0 4 2 5 4 4 0 0 5 0 2 4 1 3 7 0 5 5 0 6 8 8 0 8 3 8 8 4 0 4 8 7]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 258 out of 2276 correct. Accuracy: 11.335676625659051.\n",
            "Predicted: [0 4 2 5 4 5 6 0 5 0 2 4 7 2 2 2 7 5 2 6 4 1 6 0 1 7 2 4 0 6 8 6]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 228 out of 2276 correct. Accuracy: 10.017574692442881.\n",
            "Predicted: [0 1 3 3 4 5 3 0 4 0 2 3 1 3 2 0 5 5 3 5 3 1 7 0 5 3 2 3 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 256 out of 2276 correct. Accuracy: 11.247803163444638.\n",
            "Predicted: [0 4 2 2 4 4 2 0 4 0 2 4 1 2 2 2 6 0 3 6 4 1 0 0 1 8 2 3 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 248 out of 2276 correct. Accuracy: 10.896309314586995.\n",
            "Predicted: [0 1 2 3 4 5 3 0 5 8 2 0 8 3 2 0 7 5 3 6 8 8 6 8 5 8 2 8 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 239 out of 2276 correct. Accuracy: 10.500878734622145.\n",
            "Predicted: [0 1 2 3 4 5 6 8 5 0 2 3 1 3 1 0 5 5 3 6 8 1 6 8 1 3 2 8 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 233 out of 2276 correct. Accuracy: 10.23725834797891.\n",
            "Predicted: [0 4 2 2 1 5 3 0 5 2 2 4 1 3 2 2 5 5 3 5 4 2 6 0 1 2 2 4 7 3 8 5]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 220 out of 2276 correct. Accuracy: 9.666080843585236.\n",
            "Predicted: [0 1 2 1 1 5 3 0 3 0 2 4 1 3 1 0 5 7 3 6 0 2 6 0 1 1 7 3 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 233 out of 2276 correct. Accuracy: 10.23725834797891.\n",
            "Predicted: [0 1 2 3 4 5 3 0 3 0 2 3 7 3 2 0 6 7 3 6 5 2 6 8 3 1 2 3 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 259 out of 2276 correct. Accuracy: 11.379613356766257.\n",
            "Predicted: [0 4 2 3 4 5 6 0 5 0 2 4 7 3 2 0 8 7 3 6 3 1 6 8 5 1 2 4 7 4 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 219 out of 2276 correct. Accuracy: 9.622144112478031.\n",
            "Predicted: [0 1 2 3 4 5 0 0 3 0 2 4 7 3 1 0 6 0 3 6 8 1 6 8 1 1 7 4 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 246 out of 2276 correct. Accuracy: 10.808435852372583.\n",
            "Predicted: [0 8 2 3 4 5 0 8 3 0 2 4 7 3 1 0 8 7 3 6 8 4 6 8 5 1 7 4 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 230 out of 2276 correct. Accuracy: 10.105448154657294.\n",
            "Predicted: [0 1 2 3 1 5 3 8 5 0 2 4 1 3 1 4 6 7 3 6 5 1 1 8 3 1 1 8 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 250 out of 2276 correct. Accuracy: 10.984182776801406.\n",
            "Predicted: [0 4 2 3 4 4 6 8 5 2 2 3 1 3 2 2 6 2 3 6 3 2 6 4 1 1 2 3 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 239 out of 2276 correct. Accuracy: 10.500878734622145.\n",
            "Predicted: [0 8 5 3 1 5 6 0 4 0 2 4 1 3 2 3 6 0 3 6 0 2 6 0 3 1 7 8 7 6 8 6]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 228 out of 2276 correct. Accuracy: 10.017574692442881.\n",
            "Predicted: [0 1 2 3 1 4 6 0 5 0 2 4 1 3 2 2 6 5 3 6 5 2 6 4 1 1 7 8 7 4 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 229 out of 2276 correct. Accuracy: 10.061511423550087.\n",
            "Predicted: [0 4 2 3 4 5 4 0 3 0 2 3 1 3 1 2 6 7 3 6 5 2 6 4 3 1 2 3 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 258 out of 2276 correct. Accuracy: 11.335676625659051.\n",
            "Predicted: [0 8 2 3 1 5 6 0 5 8 2 4 1 3 1 2 6 7 3 6 8 2 6 8 8 1 7 8 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 225 out of 2276 correct. Accuracy: 9.885764499121265.\n",
            "Predicted: [0 1 5 3 4 5 0 0 4 0 2 4 1 3 1 0 6 0 3 6 5 1 6 4 8 1 7 4 7 4 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 246 out of 2276 correct. Accuracy: 10.808435852372583.\n",
            "Predicted: [0 8 5 3 1 5 6 0 3 0 2 3 1 3 1 2 6 0 3 6 8 2 6 4 3 1 7 3 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 232 out of 2276 correct. Accuracy: 10.193321616871705.\n",
            "Predicted: [0 8 5 2 1 5 6 0 5 0 2 4 1 3 1 0 8 7 3 6 0 2 6 0 8 1 7 8 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 237 out of 2276 correct. Accuracy: 10.413005272407732.\n",
            "Predicted: [0 1 5 3 1 3 6 0 3 0 2 4 1 3 7 0 8 7 3 6 1 2 6 1 8 1 2 8 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 240 out of 2276 correct. Accuracy: 10.54481546572935.\n",
            "Predicted: [0 8 5 3 1 3 0 0 3 0 2 4 1 3 1 2 6 7 3 6 1 2 6 4 8 1 2 8 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 240 out of 2276 correct. Accuracy: 10.54481546572935.\n",
            "Predicted: [0 1 5 3 1 5 0 0 3 0 2 4 1 3 1 2 6 0 3 5 1 2 5 4 8 1 2 4 7 4 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 243 out of 2276 correct. Accuracy: 10.676625659050968.\n",
            "Predicted: [0 8 5 3 4 5 6 0 3 0 2 4 1 3 1 2 6 7 3 6 1 2 6 4 8 1 7 4 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 248 out of 2276 correct. Accuracy: 10.896309314586995.\n",
            "Predicted: [0 8 5 3 4 5 0 7 3 0 2 4 1 3 1 2 6 7 3 6 1 2 6 8 8 1 7 3 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 239 out of 2276 correct. Accuracy: 10.500878734622145.\n",
            "Predicted: [0 8 5 3 4 5 0 0 3 0 2 4 1 3 1 2 6 7 3 6 0 2 6 4 8 1 7 3 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 249 out of 2276 correct. Accuracy: 10.9402460456942.\n",
            "Predicted: [0 8 5 3 4 5 0 0 3 0 2 4 1 3 1 4 8 7 3 6 1 2 5 4 8 1 7 4 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 238 out of 2276 correct. Accuracy: 10.456942003514937.\n",
            "Predicted: [0 8 5 3 1 5 6 0 3 0 2 3 1 3 1 2 8 7 3 6 0 2 5 4 8 1 7 3 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 251 out of 2276 correct. Accuracy: 11.028119507908611.\n",
            "Predicted: [0 8 5 3 4 5 0 0 3 0 2 4 1 3 0 0 6 7 3 6 0 2 6 4 8 1 7 3 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 239 out of 2276 correct. Accuracy: 10.500878734622145.\n",
            "Predicted: [0 8 5 3 4 5 0 0 3 0 2 3 1 3 0 0 6 7 3 6 3 2 5 0 8 1 7 3 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 244 out of 2276 correct. Accuracy: 10.720562390158172.\n",
            "Predicted: [0 8 5 3 1 5 0 0 3 0 2 3 1 3 0 0 6 7 3 6 0 2 6 4 8 1 7 3 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 244 out of 2276 correct. Accuracy: 10.720562390158172.\n",
            "Predicted: [0 8 5 3 1 5 0 0 3 0 2 4 1 3 0 0 6 7 3 6 0 2 6 0 8 1 7 3 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 241 out of 2276 correct. Accuracy: 10.588752196836555.\n",
            "Predicted: [0 8 5 3 1 5 0 0 3 0 2 4 1 3 1 0 6 7 3 6 0 2 6 4 8 1 7 3 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 244 out of 2276 correct. Accuracy: 10.720562390158172.\n",
            "Predicted: [3 8 5 3 1 5 0 0 3 0 2 3 1 3 0 0 6 7 3 6 1 2 6 4 8 1 7 3 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 237 out of 2276 correct. Accuracy: 10.413005272407732.\n",
            "Predicted: [0 8 5 3 1 5 0 0 3 0 2 4 1 3 0 0 6 7 3 6 0 2 6 4 8 1 7 3 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 241 out of 2276 correct. Accuracy: 10.588752196836555.\n",
            "Predicted: [0 8 5 3 4 5 0 0 3 0 2 4 1 3 0 0 6 7 3 6 1 2 6 4 8 1 7 4 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 251 out of 2276 correct. Accuracy: 11.028119507908611.\n",
            "Predicted: [0 8 5 3 1 5 0 0 3 0 2 4 1 3 0 0 6 7 3 6 1 2 6 4 8 1 7 3 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 245 out of 2276 correct. Accuracy: 10.764499121265377.\n",
            "Predicted: [0 8 5 3 1 5 0 0 3 0 2 4 1 3 0 0 8 7 3 6 1 2 6 4 8 1 7 3 7 3 8 1]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 240 out of 2276 correct. Accuracy: 10.54481546572935.\n",
            "Predicted: [3 8 5 3 4 5 0 0 3 0 2 4 1 3 0 0 6 7 3 6 3 2 6 4 8 1 7 3 7 3 8 3]\n",
            "Actual:    [5 1 1 0 3 3 2 6 4 5 8 0 8 5 8 2 3 6 5 7 6 7 7 2 4 1 0 8 3 0 1 5]\n",
            "Got 245 out of 2276 correct. Accuracy: 10.764499121265377.\n",
            "Saved fine-tuned weights to ./weight/mydata_patients_train_MIRepNet_finetuned.pth\n",
            "Results saved to ./result/acc/mydata_patients_train_MIRepNet_2025-10-24_00-30-38_results.csv\n",
            "Experiment completed successfully\n"
          ]
        }
      ]
    }
  ]
}