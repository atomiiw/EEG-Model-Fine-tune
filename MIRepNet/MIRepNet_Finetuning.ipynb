{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "atw1Sidiy64K",
        "xKm5Q8Tu0yuv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the folder"
      ],
      "metadata": {
        "id": "atw1Sidiy64K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npA0ADiOcx9w",
        "outputId": "344d126f-c653-48e7-c9cc-87dec3f9ccd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/atomiiw/EEG-Model-Fine-tune.git"
      ],
      "metadata": {
        "id": "fnuMqE_u9RiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f82643-1e8d-451d-bf94-2e2148b90493"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EEG-Model-Fine-tune'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 67 (delta 24), reused 41 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (67/67), 972.07 KiB | 1.12 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd EEG-Model-Fine-tune/MIRepNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tamWZhTF0O1",
        "outputId": "37efc94b-8855-4fc2-c49b-866b91ec35ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EEG-Model-Fine-tune/MIRepNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "x3hU08tSF3hw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdQ3UolX_q14",
        "outputId": "41634a8f-5c84-49fb-b6a4-624cc1dc1902"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtk3mOLlJ49j",
        "outputId": "fd41adb6-fc91-4096-a08b-17d3141f2ef0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34masset\u001b[0m/       LICENSE                    README.md         \u001b[01;34mutils\u001b[0m/\n",
            "dataset.py   MIRepNet_Finetuning.ipynb  requirements.txt\n",
            "finetune.py  \u001b[01;34mmodel\u001b[0m/                     results.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Performance: Before Fine-tuning\n",
        "Current output: among {0, 1, 2, 3}   \n",
        "Expected output: among {0, 1, ..., 7, 8}   \n",
        "Current accuracy: 8%-15%   \n",
        "Accuracy if just randomly guessing: 11%     \n",
        "\n",
        "Why does accuracy differ every time?  \n",
        "'Loaded 108/110 parameters from pretrained model'   \n",
        "The 2 final layer weights are randomly initialized\n"
      ],
      "metadata": {
        "id": "xKm5Q8Tu0yuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from model.mlm import mlm_mask\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ==== CONFIG ====\n",
        "DATASET_NAME = \"basic\"\n",
        "WEIGHT_PATH = \"weight/MIRepNet.pth\"   # pretrained weights (4-class)\n",
        "BATCH_SIZE = 32\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ==== LOAD DATA ====\n",
        "X = np.load(f'data/{DATASET_NAME}/X_test.npy')   # (N, 128, 200)\n",
        "y = np.load(f'data/{DATASET_NAME}/labels_test.npy')  # (N,)\n",
        "print(\"Loaded data:\", X.shape, y.shape)\n",
        "\n",
        "# convert to tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# ==== LOAD MODEL ====\n",
        "model = mlm_mask(\n",
        "    emb_size=256,\n",
        "    depth=6,\n",
        "    n_classes=4,     # pretrained model expects 4 outputs\n",
        "    pretrainmode=False,\n",
        "    pretrain=WEIGHT_PATH\n",
        ").to(DEVICE)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# ==== EVALUATE ====\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, labels in loader:\n",
        "        data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
        "        _, outputs = model(data)\n",
        "        # expected to return amongst {0, 1, 2, 3}\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = correct / total * 100\n",
        "print(f\"\\n‚úÖ Raw pretrained MIRepNet accuracy on your dataset: {accuracy:.2f}%\")\n",
        "print(f\"Correct: {correct} / {total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E55nG5tE0x0h",
        "outputId": "384a7555-34fb-498d-d72b-3a54c8b36c37"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded data: (144, 128, 200) (144,)\n",
            "Loaded 108/110 parameters from pretrained model\n",
            "\n",
            "‚úÖ Raw pretrained MIRepNet accuracy on your dataset: 8.33%\n",
            "Correct: 12 / 144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train across all patients"
      ],
      "metadata": {
        "id": "Y-Fsq8PizA7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python finetune.py --dataset_name basic --model_name MIRepNet --num_classes 9 --val_split 0.8 --epochs 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW_AjaqWdwCg",
        "outputId": "00cd1e05-0d20-475a-ed5f-ce6e670f4d36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting EEG Classification with Configurable Hyperparameters\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/EEG-Model-Fine-tune/MIRepNet/finetune.py\", line 67, in <module>\n",
            "    log_file = open(\n",
            "               ^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './result/log/basic_MIRepNet_2025-11-06_17-14-10_log.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train on each patient individually\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SqCPyN39_vSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python finetune.py --dataset_name S14_testing --model_name MIRepNet --num_classes 9 --val_split 0.2 --epochs 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTMSqaMV_zR4",
        "outputId": "6a836e1e-4adc-4372-b357-342613fee774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting EEG Classification with Configurable Hyperparameters\n",
            "\n",
            "original data shape: (1000, 128, 200) labels shape: (1000,)\n",
            "preprocessed data shape: (1000, 128, 200) preprocessed labels shape: (1000,)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "üîß Using local process_and_replace_loader from finetune.py\n",
            "üîß Using local process_and_replace_loader from finetune.py\n",
            "‚úÖ Saved EA matrix to ./weight/S14_testing_EA_matrix.npy\n",
            "Loaded 108/110 parameters from pretrained model\n",
            "Seed: 666, Subject: 0\n",
            "\n",
            "Predicted: [1 3 7 1 4 2 0 0 4 1 6 1 3 1 1 4 4 0 4 1 4 0 2 1 7 8 7 4 4 4 4 7]\n",
            "Actual:    [1 3 8 0 3 2 0 0 5 3 6 6 3 0 1 4 4 0 6 1 6 0 2 5 7 1 7 5 4 4 5 7]\n",
            "Got 125 out of 200 correct. Accuracy: 62.5.\n",
            "Predicted: [1 3 7 0 3 2 0 0 5 3 6 6 3 5 1 4 4 0 6 1 6 0 2 5 7 8 2 3 4 4 3 7]\n",
            "Actual:    [1 3 8 0 3 2 0 0 5 3 6 6 3 0 1 4 4 0 6 1 6 0 2 5 7 1 7 5 4 4 5 7]\n",
            "Got 169 out of 200 correct. Accuracy: 84.5.\n",
            "Predicted: [1 3 8 0 3 2 0 0 5 3 6 6 3 0 1 4 4 0 6 1 6 0 2 5 7 1 7 5 4 4 5 7]\n",
            "Actual:    [1 3 8 0 3 2 0 0 5 3 6 6 3 0 1 4 4 0 6 1 6 0 2 5 7 1 7 5 4 4 5 7]\n",
            "Got 193 out of 200 correct. Accuracy: 96.5.\n",
            "Predicted: [1 3 8 0 3 2 0 0 5 3 6 6 3 0 1 4 4 0 6 1 6 0 2 5 7 1 8 5 4 4 5 7]\n",
            "Actual:    [1 3 8 0 3 2 0 0 5 3 6 6 3 0 1 4 4 0 6 1 6 0 2 5 7 1 7 5 4 4 5 7]\n",
            "Got 196 out of 200 correct. Accuracy: 98.0.\n",
            "Predicted: [1 3 8 0 3 2 0 0 5 3 6 6 3 0 1 4 4 0 6 1 6 0 2 5 7 1 7 5 4 4 5 7]\n",
            "Actual:    [1 3 8 0 3 2 0 0 5 3 6 6 3 0 1 4 4 0 6 1 6 0 2 5 7 1 7 5 4 4 5 7]\n",
            "Got 200 out of 200 correct. Accuracy: 100.0.\n",
            "Saved fine-tuned weights to ./weight/S14_testing_MIRepNet_finetuned.pth\n",
            "Results saved to ./result/acc/S14_testing_MIRepNet_2025-10-31_03-08-00_results.csv\n",
            "Experiment completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test on the training data"
      ],
      "metadata": {
        "id": "3jwoWlye7I05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from scipy.linalg import fractional_matrix_power\n",
        "from model.mlm import mlm_mask\n",
        "from utils.channel_list import use_channels_names, channel_positions\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "# ==== CONFIG ====\n",
        "DATASET_NAME = \"S14_testing\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ==== Load data ====\n",
        "X = np.load(f\"data/{DATASET_NAME}/X.npy\")  # (N,128,200)\n",
        "y = np.load(f\"data/{DATASET_NAME}/labels.npy\")\n",
        "\n",
        "# ==== 1Ô∏è‚É£ Apply Euclidean Alignment (exactly same direction) ====\n",
        "refEA = np.load(f\"weight/{DATASET_NAME}_EA_matrix.npy\")\n",
        "X_ea = np.zeros_like(X)\n",
        "for i in range(X.shape[0]):\n",
        "    X_ea[i] = np.dot(refEA, X[i])    # same as training (not transposed)\n",
        "\n",
        "# ==== 2Ô∏è‚É£ Channel interpolation to 45 channels ====\n",
        "def pad_missing_channels_diff(x, target_channels, actual_channels):\n",
        "    B, C, T = x.shape\n",
        "    existing_pos = np.array([channel_positions[ch] for ch in actual_channels])\n",
        "    target_pos = np.array([channel_positions[ch] for ch in target_channels])\n",
        "\n",
        "    W = np.zeros((len(target_channels), C))\n",
        "    for i, (target_ch, pos) in enumerate(zip(target_channels, target_pos)):\n",
        "        if target_ch in actual_channels:\n",
        "            src_idx = actual_channels.index(target_ch)\n",
        "            W[i, src_idx] = 1.0\n",
        "        else:\n",
        "            dist = cdist([pos], existing_pos)[0]\n",
        "            weights = 1 / (dist + 1e-6)\n",
        "            weights /= weights.sum()\n",
        "            W[i] = weights\n",
        "\n",
        "    padded = np.zeros((B, len(target_channels), T))\n",
        "    for b in range(B):\n",
        "        padded[b] = W @ x[b]\n",
        "    return padded\n",
        "\n",
        "X_final = pad_missing_channels_diff(X_ea, use_channels_names, use_channels_names)\n",
        "print(\"Shape after projection:\", X_final.shape)  # (N,45,200)\n",
        "\n",
        "# ==== 3Ô∏è‚É£ Convert to tensors ====\n",
        "X_tensor = torch.tensor(X_final, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "loader = DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=32)\n",
        "\n",
        "# ==== 4Ô∏è‚É£ Load model ====\n",
        "model = mlm_mask(emb_size=256, depth=6, n_classes=9, pretrainmode=False).to(DEVICE)\n",
        "model.load_state_dict(torch.load(f\"weight/{DATASET_NAME}_MIRepNet_finetuned.pth\", map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "# ==== 5Ô∏è‚É£ Evaluate ====\n",
        "correct = total = 0\n",
        "with torch.no_grad():\n",
        "    for data, labels in loader:\n",
        "        data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
        "        _, outputs = model(data)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "acc = correct / total * 100\n",
        "print(f\"‚úÖ Test accuracy on {DATASET_NAME}: {acc:.2f}% ({correct}/{total})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve19iQ1K7Q47",
        "outputId": "b05c47f2-1e8b-4325-946d-e47048d769e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after projection: (1000, 45, 200)\n",
            "‚úÖ Test accuracy on S14_testing: 100.00% (1000/1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test on unseen data from the same patient"
      ],
      "metadata": {
        "id": "DigTHzdmMNiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from scipy.linalg import fractional_matrix_power\n",
        "from model.mlm import mlm_mask\n",
        "from utils.channel_list import use_channels_names, channel_positions\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "# ==== CONFIG ====\n",
        "DATASET_NAME = \"S14\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ==== Load data ====\n",
        "X = np.load(f\"data/{DATASET_NAME}/X_test.npy\")  # (N,128,200)\n",
        "y = np.load(f\"data/{DATASET_NAME}/labels_test.npy\")\n",
        "\n",
        "# ==== 1Ô∏è‚É£ Apply Euclidean Alignment (exactly same direction) ====\n",
        "refEA = np.load(f\"weight/S14_testing_EA_matrix.npy\")\n",
        "X_ea = np.zeros_like(X)\n",
        "for i in range(X.shape[0]):\n",
        "    X_ea[i] = np.dot(refEA, X[i])    # same as training (not transposed)\n",
        "\n",
        "# ==== 2Ô∏è‚É£ Channel interpolation to 45 channels ====\n",
        "def pad_missing_channels_diff(x, target_channels, actual_channels):\n",
        "    B, C, T = x.shape\n",
        "    existing_pos = np.array([channel_positions[ch] for ch in actual_channels])\n",
        "    target_pos = np.array([channel_positions[ch] for ch in target_channels])\n",
        "\n",
        "    W = np.zeros((len(target_channels), C))\n",
        "    for i, (target_ch, pos) in enumerate(zip(target_channels, target_pos)):\n",
        "        if target_ch in actual_channels:\n",
        "            src_idx = actual_channels.index(target_ch)\n",
        "            W[i, src_idx] = 1.0\n",
        "        else:\n",
        "            dist = cdist([pos], existing_pos)[0]\n",
        "            weights = 1 / (dist + 1e-6)\n",
        "            weights /= weights.sum()\n",
        "            W[i] = weights\n",
        "\n",
        "    padded = np.zeros((B, len(target_channels), T))\n",
        "    for b in range(B):\n",
        "        padded[b] = W @ x[b]\n",
        "    return padded\n",
        "\n",
        "X_final = pad_missing_channels_diff(X_ea, use_channels_names, use_channels_names)\n",
        "print(\"Shape after projection:\", X_final.shape)  # (N,45,200)\n",
        "\n",
        "# ==== 3Ô∏è‚É£ Convert to tensors ====\n",
        "X_tensor = torch.tensor(X_final, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "loader = DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=32)\n",
        "\n",
        "# ==== 4Ô∏è‚É£ Load model ====\n",
        "model = mlm_mask(emb_size=256, depth=6, n_classes=9, pretrainmode=False).to(DEVICE)\n",
        "model.load_state_dict(torch.load(f\"weight/{DATASET_NAME}_MIRepNet_finetuned.pth\", map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "# ==== 5Ô∏è‚É£ Evaluate ====\n",
        "correct = total = 0\n",
        "with torch.no_grad():\n",
        "    for data, labels in loader:\n",
        "        data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
        "        _, outputs = model(data)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "acc = correct / total * 100\n",
        "print(f\"‚úÖ Test accuracy on {DATASET_NAME}: {acc:.2f}% ({correct}/{total})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUefGnDgMSnY",
        "outputId": "6d11ee35-e332-4ad5-b55a-544504bd3935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after projection: (44, 45, 200)\n",
            "‚úÖ Test accuracy on S14: 54.55% (24/44)\n"
          ]
        }
      ]
    }
  ]
}